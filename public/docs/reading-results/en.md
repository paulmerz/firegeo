## Understanding the Results

The "Reading Results" page consolidates the analyses produced by your AI providers (OpenAI, Anthropic, Google, Perplexity, etc.) to explain how your brand is perceived. Use the sidebar to navigate the four modules: start with the AI narrative, move through the competitive comparison, and finish with the visibility score.

### Prompts & Responses: Analyze the AI Narrative

**Goal:** Review each question asked, the detailed response from each model, and the passages that cite your brand or competitors.

**What to look for:**
- "Web Search enabled" banner when live web search enriched the answer with fresh sources.
- Automatic highlights of your brand and each competitor to spot key arguments in seconds.
- Expand/collapse control to show or hide the full response, plus an internal search to filter prompts by keyword.
- "Web search sources" box listing cited articles so you can trace answers back to original content.

**Marketing actions:**
- Check whether AIs convey your intended positioning and adjust messaging if needed.
- Identify benefits attributed to competitors to fuel campaigns or sales enablement.
- Spot questions that trigger weak or missing answers: they reveal areas where you should strengthen your online presence.

### Comparison Matrix: Measure Your Share of Voice

**Goal:** Visualize, in a single table, how much each AI provider mentions each brand and detect major gaps.

**What to look for:**
- Columns by provider (OpenAI, Anthropic, Google, Perplexity...) with their logo to quickly identify channels that favor you.
- Colors from neutral to dark orange to represent mention intensity; a high score means the model frequently cites the brand.
- Dynamic sorting by column to rank brands by score and compare your performance per provider.
- Top-right block "Average score": mirrors your brand's overall visibility score (see definition below).

**How are the percentages calculated?**
- `12.5%` in the OpenAI column means the brand appears in 12.5% of the answers returned by OpenAI. Example: 5 answers mention your brand out of 40 total answers = 5 / 40 * 100.
- The "Average score" corresponds to the overall percentage of answers that cite your brand, across all providers. It is recalculated for each new campaign.
- Cells also display the raw number of mentions (on hover) to understand the volume behind the percentage.

**Marketing actions:**
- Identify which providers favor you and prioritize efforts (PR, SEO content, product pages) on those channels.
- Find places where you are less visible to guide marketing investments or challenge your data partners.
- Track evolution after a campaign and check whether your share of voice improves with targeted models.

### Provider Rankings: Understand Your Position

**Goal:** Consult the detailed podium each AI model builds for your category and track your key indicators.

**What to look for:**
- One tab per provider with the ranking, your position (highlighted in orange), and the weekly change when available.
- For each brand: visibility score, share of voice, and overall sentiment (positive, neutral, or negative badge).
- A numerical recap at the bottom (number of tracked competitors, your rank and visibility, average sentiment, share of voice, average position).

**Column definitions:**
- `Visibility score`: percentage of provider responses that cite the brand (same calculation as the matrix, but scoped to the provider tab).
- `Share of Voice`: share of mentions captured by a brand out of all mentions recorded for this provider. Example: if OpenAI cites brands 20 times and 4 of those mentions concern your company, your OpenAI share of voice is 20%.
- `Sentiment` and `Sentiment score`: average of detected tones in responses (positive = 100, neutral = 50, negative = 0, rounded average).
- `Average position`: average rank when the provider outputs an explicit ordering (lower is better).

**Marketing actions:**
- Monitor fast rises or drops to trigger a root-cause analysis (campaigns, news, competitor launch).
- Compare displayed sentiments to detect topics that drive advocacy or distrust.
- Use these rankings in internal reporting to prove the impact of your actions to stakeholders.

### Visibility Score: Get a Global Measure

**Goal:** Track the consolidated indicator combining mention volume and tone to estimate your brand's overall impact with AIs.

**What to look for:**
- A donut chart comparing your score to key competitors and highlighting your position (#1, #2, etc.).
- The numeric gap with the leader to immediately see the effort needed to move ahead.
- The legend listing up to eight brands with their individual scores and, when available, their favicon or initial for quick recognition.

**Calculation method:**
- A brand's `Visibility score` = (number of answers that mention the brand / total number of answers analyzed) * 100, rounded to one decimal place. This indicator exists at two levels: global (all providers) and per provider (in the matrix and rankings).
- The `Global score` (labeled "Global Score" in the tab) weights multiple signals: 30% visibility score, 30% share of voice, 20% average sentiment, and 20% average position converted to a 0â€“100 scale. This gives you a synthetic view of your footprint across AIs.
- The "+X% vs #1" gap indicates the difference in visibility score between your brand and the top brand.

**Marketing actions:**
- Base quarterly objectives on the visibility score to align a single KPI across comms and product teams.
- Cross this indicator with sales or inbound leads to measure correlation between AI visibility and conversions.
- When you see a drop, go back to the previous tabs to identify which prompts or providers explain it.

### Go Further
- Use the "Analyze another website" button to relaunch a study after content updates or a campaign.
- Check consumed and available credits regularly (shown in the analysis header) to plan next operations.
- Export key takeaways to your reporting tools and share with content, SEO, or PR teams.
